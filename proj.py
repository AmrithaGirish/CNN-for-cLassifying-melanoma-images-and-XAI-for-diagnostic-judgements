# -*- coding: utf-8 -*-
"""Proj.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1xwLlw2Ej861j7F6zqNkZfEeDdNr6alkp
"""

# Commented out IPython magic to ensure Python compatibility.
import tensorflow as tf
import os
import numpy as np
import matplotlib.pyplot as plt
import re
import random
import cv2
import tensorflow as tf
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from keras.utils.np_utils import to_categorical
import re
import random
import cv2
import json
import math
import os
import cv2
from PIL import Image
import numpy as np
from keras import layers
from tensorflow import keras
#from keras.applications import ResNet50,MobileNet, DenseNet201, InceptionV3, NASNetLarge, InceptionResNetV2, NASNetMobile
#from keras.applications.resnet50 import ResNet50
from tensorflow.keras.applications.resnet50 import ResNet50
from keras.callbacks import Callback, ModelCheckpoint, ReduceLROnPlateau, TensorBoard
from keras.preprocessing.image import ImageDataGenerator
from keras.utils.np_utils import to_categorical
from keras.models import Sequential
#from keras.optimizers import Adam
from tensorflow.keras.optimizers import Adam
import matplotlib.pyplot as plt
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.metrics import cohen_kappa_score, accuracy_score
import scipy
from tqdm import tqdm
import tensorflow as tf
from keras import backend as K
import gc
from functools import partial
from sklearn import metrics
from collections import Counter
import json
import itertools
# %matplotlib inline

from google.colab import drive
drive.mount('/content/drive')

def Dataset_loader(DIR, RESIZE, sigmaX=10):
    IMG = []
    read = lambda imname: np.asarray(Image.open(imname).convert("RGB"))
    for IMAGE_NAME in tqdm(os.listdir(DIR)):
        PATH = os.path.join(DIR,IMAGE_NAME)
        _, ftype = os.path.splitext(PATH)
        if ftype == ".jpg":
            img = read(PATH)
           
            img = cv2.resize(img, (RESIZE,RESIZE))
           
            IMG.append(np.array(img))
    return IMG

B_tr = np.array(Dataset_loader('/content/drive/MyDrive/Btrain',224))
M_tr = np.array(Dataset_loader('/content/drive/MyDrive/Mtrain',224))
B_val =np.array(Dataset_loader('/content/drive/MyDrive/Btest',224))
M_val =np.array(Dataset_loader('/content/drive/MyDrive/Mtrain',224))

benign_train_label = np.zeros(len(B_tr))
malign_train_label = np.ones(len(M_tr))
benign_test_label = np.zeros(len(B_val))
malign_test_label = np.ones(len(M_val)) 

X_train = np.concatenate((B_tr, M_tr), axis = 0)
Y_train = np.concatenate((benign_train_label, malign_train_label), axis = 0)
X_test = np.concatenate((B_val, M_val), axis = 0)
Y_test = np.concatenate((benign_test_label, malign_test_label), axis = 0)

s = np.arange(X_train.shape[0])
np.random.shuffle(s)
X_train = X_train[s]
Y_train = Y_train[s]

s = np.arange(X_test.shape[0])
np.random.shuffle(s)
X_test = X_test[s]
Y_test = Y_test[s]

Y_train = to_categorical(Y_train, num_classes= 2)
Y_test = to_categorical(Y_test, num_classes= 2)

x_train, x_val, y_train, y_val = train_test_split(
    X_train, Y_train, 
    test_size=0.2, 
    random_state=11
)

w=60
h=40
fig=plt.figure(figsize=(15, 15))
columns = 4
rows = 3

for i in range(1, columns*rows +1):
    ax = fig.add_subplot(rows, columns, i)
    if np.argmax(Y_train[i]) == 0:
        ax.title.set_text('Benign')
    else:
        ax.title.set_text('Malignant')
    plt.imshow(X_train[i], interpolation='nearest')
plt.show()

BATCH_SIZE = 64

train_generator = ImageDataGenerator(
        zoom_range=2, 
        rotation_range = 90,
        horizontal_flip=True, 
        vertical_flip=True, 
    )

def create_model(backbone, lr=5e-4):
    model = Sequential()
    model.add(backbone)
    model.add(layers.GlobalAveragePooling2D())
    model.add(layers.Dropout(0.5))
    model.add(layers.BatchNormalization())
    model.add(layers.Dense(2, activation='softmax'))
    
    
    model.compile(
        loss='binary_crossentropy',
        optimizer=Adam(lr=lr),
        metrics=['accuracy']
    )
    
    return model

learn_control = ReduceLROnPlateau(monitor='val_acc', patience=5,
                                  verbose=1,factor=0.2, min_lr=1e-7)

filepath="weights.best.hdf5"
checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')

batch_size = 32
#epochs = 10
def fit_model(model):
    history = model.fit_generator(
    train_generator.flow(x_train, y_train, batch_size=BATCH_SIZE),
    steps_per_epoch=x_train.shape[0] / BATCH_SIZE,
    epochs=10,
    validation_data=(x_val, y_val),
    callbacks=[learn_control, checkpoint]
)
    return history
    
def plot_history(history):
    acc = history.history['accuracy']
    val_acc = history.history['val_accuracy']

    loss=history.history['loss']
    val_loss=history.history['val_loss']

    epochs_range = range(epochs)

    plt.figure(figsize=(12, 6))
    plt.subplot(1, 2, 1)
    plt.plot(epochs_range, acc, label='Training Accuracy')
    plt.plot(epochs_range, val_acc, label='Validation Accuracy')
    plt.legend(loc='lower right')
    plt.title('Training and Validation Accuracy')

    plt.subplot(1, 2, 2)
    plt.plot(epochs_range, loss, label='Training Loss')
    plt.plot(epochs_range, val_loss, label='Validation Loss')
    plt.legend(loc='upper right')
    plt.title('Training and Validation Loss')
    plt.show()

IMG_SHAPE = (224, 224, 3)
base_model1 = tf.keras.applications.ResNet50(input_shape=IMG_SHAPE, include_top=False, weights="imagenet")
base_model2 = tf.keras.applications.InceptionV3(input_shape=IMG_SHAPE, include_top=False, weights="imagenet")
base_model3 = tf.keras.applications.MobileNetV2(input_shape=IMG_SHAPE, include_top=False, weights="imagenet")
model1 = create_model(base_model1)
model2 = create_model(base_model2)
model3 = create_model(base_model3)
history1 = fit_model(model1)
model1.save('models/model1.h5')
history2 = fit_model(model2)
model2.save('models/model2.h5')
history3 = fit_model(model3)
model3.save('models/model3.h5')

with open('history.json', 'w') as f:
    json.dump(str(history1.history), f)
history_df = pd.DataFrame(history1.history)
history_df[['accuracy', 'val_accuracy']].plot()

with open('history.json', 'w') as f:
    json.dump(str(history1.history), f)
history_df = pd.DataFrame(history3.history)
history_df[['loss', 'val_loss']].plot()

with open('history.json', 'w') as f:
    json.dump(str(history2.history), f)
history_df = pd.DataFrame(history2.history)
history_df[['accuracy', 'val_accuracy']].plot()

with open('history.json', 'w') as f:
    json.dump(str(history2.history), f)
history_df = pd.DataFrame(history3.history)
history_df[['loss', 'val_loss']].plot()

with open('history.json', 'w') as f:
    json.dump(str(history3.history), f)
history_df = pd.DataFrame(history3.history)
history_df[['accuracy', 'val_accuracy']].plot()

with open('history.json', 'w') as f:
    json.dump(str(history3.history), f)
history_df = pd.DataFrame(history3.history)
history_df[['loss', 'val_loss']].plot()

def load_all_models():
    all_models = []
    model_names = ['model1.h5', 'model2.h5', 'model3.h5']
    for model_name in model_names:
        filename = os.path.join('models', model_name)
        model = tf.keras.models.load_model(filename)
        all_models.append(model)
        print('loaded:', filename)
    return all_models

def ensemble_model(models):
    for i, model in enumerate(models):
        for layer in model.layers:
            layer.trainable = False
    ensemble_visible = [model.input for model in models]
    ensemble_outputs = [model.output for model in models]
    merge = tf.keras.layers.concatenate(ensemble_outputs)
    merge = tf.keras.layers.Dense(10, activation='relu')(merge)
    output = tf.keras.layers.Dense(1, activation='sigmoid')(merge)
    model = tf.keras.models.Model(inputs=ensemble_visible, outputs=output)
    model.compile(optimizer=tf.keras.optimizers.Adam(lr=0.0363), loss=tf.keras.losses.BinaryCrossentropy(from_logits=True), metrics=["accuracy"])
    return model

models = load_all_models()
model = ensemble_model(models)

X = [X_train for _ in range(len(model.input))]
X_1 = [X_test for _ in range(len(model.input))]

PATH = os.path.abspath("/content/drive/MyDrive/data2")

train_dir = os.path.join(PATH, 'train')
validation_dir = os.path.join(PATH, 'test')

train_benign_dir = os.path.join(train_dir, 'benign')  # directory with our training Benign pictures
train_malignant_dir = os.path.join(train_dir, 'malignant')  # directory with our training malig pictures
validation_benign_dir = os.path.join(validation_dir, 'benign')  # directory with our validation ben pictures
validation_malignant_dir = os.path.join(validation_dir, 'malignant')  # directory with our validation mal pictures

B_tr = os.listdir(train_benign_dir)
M_tr = os.listdir(train_malignant_dir)

B_val = os.listdir(validation_benign_dir)
M_val = os.listdir(validation_malignant_dir)

B_tr = [os.path.join(train_benign_dir, x) for x in B_tr]
M_tr = [os.path.join(train_malignant_dir, x) for x in M_tr]
B_val = [os.path.join(validation_benign_dir, x) for x in B_val]
M_val = [os.path.join(validation_malignant_dir, x) for x in M_val]

total_train = B_tr + M_tr
total_val = B_val + M_val

random.shuffle(total_train)
X_train = np.zeros((len(total_train), 224, 224, 3)).astype('float')
y_train = []
for i, img_path in enumerate(total_train):
    img = cv2.imread(img_path)
    img = cv2.resize(img, (224, 224))
    X_train[i] = img
    if len(re.findall('malignant', img_path)) == 3:
        y_train.append(0)
    else: 
        y_train.append(1)
y_train = np.array(y_train)

random.shuffle(total_val)
X_test = np.zeros((len(total_val), 224, 224, 3)).astype('float')
y_test = []
for i, img_path in enumerate(total_val):
    img = cv2.imread(img_path)
    img = cv2.resize(img, (224, 224))
    X_test[i] = img
    if len(re.findall('malignant', img_path)) == 3:
        y_test.append(0)
    else: 
        y_test.append(1)
y_test = np.array(y_test)

batch_size = 32
epochs = 20
IMG_HEIGHT = 224
IMG_WIDTH = 224

def load_all_models():
    all_models = []
    model_names = ['model1.h5', 'model2.h5', 'model3.h5']
    for model_name in model_names:
        filename = os.path.join('models', model_name)
        model = tf.keras.models.load_model(filename)
        all_models.append(model)
        print('loaded:', filename)
    return all_models

def ensemble_model(models):
    for i, model in enumerate(models):
        for layer in model.layers:
            layer.trainable = False
    ensemble_visible = [model.input for model in models]
    ensemble_outputs = [model.output for model in models]
    merge = tf.keras.layers.concatenate(ensemble_outputs)
    merge = tf.keras.layers.Dense(10, activation='relu')(merge)
    output = tf.keras.layers.Dense(1, activation='sigmoid')(merge)
    model = tf.keras.models.Model(inputs=ensemble_visible, outputs=output)
    model.compile(optimizer=tf.keras.optimizers.Adam(lr=0.0393), loss=tf.keras.losses.BinaryCrossentropy(from_logits=True), metrics=["accuracy"])
    return model

models = load_all_models()
model = ensemble_model(models)

X = [X_train for _ in range(len(model.input))]
#Y=[Y_train for _ in range(len(model.input))]
#Y_1=[Y_test for _ in range(len(model.input))]
X_1 = [X_test for _ in range(len(model.input))]

epochs = 20
history = model.fit(X, y_train,
                    batch_size=batch_size,
                    steps_per_epoch=len(total_train) // batch_size,
                    epochs=epochs,
                    validation_data=(X_1, y_train),
                    validation_steps=len(total_val) // batch_size
                    )

model.save('models/model.h5')

with open('history.json', 'w') as f:
    json.dump(str(history.history), f)
history_df = pd.DataFrame(history.history)
history_df[['accuracy','val_accuracy']].plot()

with open('history.json', 'w') as f:
    json.dump(str(history.history), f)
history_df = pd.DataFrame(history.history)
history_df[['loss', 'val_loss']].plot()

print('ResNet50 acc acc:', history1.history['val_accuracy'][-1])
print('InceptionV3 acc:', history2.history['val_accuracy'][-1])
print('MobileNetV2 acc:', history3.history['val_accuracy'][-1])
print('Ensemble acc:', history.history['val_accuracy'][-1])

Y_val_pred = model.predict(X)

Y_pred = model.predict(X_1)

tta_steps = 10
predictions = []

for i in tqdm(range(tta_steps)):
    preds = model1.predict_generator(train_generator.flow(X_test, batch_size=BATCH_SIZE, shuffle=False),
                                    steps = len(X_test)/BATCH_SIZE)
    
    predictions.append(preds)
    gc.collect()
    
Y_pred_tta = np.mean(predictions, axis=0)

i=0
prop_class=[]
mis_class=[]

for i in range(len(Y_test)):
    if(np.argmax(Y_test[i])==np.argmax(Y_pred_tta[i])):
        prop_class.append(i)
    if(len(prop_class)==8):
        break

i=0
for i in range(len(Y_test)):
    if(not np.argmax(Y_test[i])==np.argmax(Y_pred_tta[i])):
        mis_class.append(i)
    if(len(mis_class)==8):
        break

w=60
h=40
fig=plt.figure(figsize=(18, 10))
columns = 4
rows = 2

def Transfername(namecode):
    if namecode==0:
        return "Benign"
    else:
        return "Malignant"
    
for i in range(len(prop_class)):
    ax = fig.add_subplot(rows, columns, i+1)
    ax.set_title("Predicted result:"+ Transfername(np.argmax(Y_pred_tta[prop_class[0]]))
                       +"\n"+"Actual result: "+ Transfername(np.argmax(Y_test[prop_class[1]])))
    plt.imshow(X_test[prop_class[i]], interpolation='nearest')
plt.show()

import tensorflow as tf
from tensorflow.keras.preprocessing.image import ImageDataGenerator

import os
import numpy as np
import matplotlib.pyplot as plt
import re
import random
import cv2

!pip install lime

eval_df = total_val
BATCH_SIZE = 64
HEIGHT = 256
WIDTH = 256
SEED = 0

train =total_train
test=total_val

from lime import lime_image

explainer = lime_image.LimeImageExplainer()

!pip install scikit-image

import skimage
from skimage import io
from tensorflow.keras.preprocessing import image

from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, Activation, BatchNormalization
from tensorflow.keras.models import Sequential, Model
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.preprocessing.image import ImageDataGenerator,DirectoryIterator
from tensorflow.keras.datasets import mnist
import numpy as np
import matplotlib.pyplot as plt
import matplotlib.image as mpimg
from keras import backend as K
import os
import tensorflow as tf

# Path to train and test directory
dir_ = os.path.abspath("/content/drive/MyDrive/data2")


# Generate training and test data with Image Generator
train_datagen = ImageDataGenerator(rescale=1/255,
                                  validation_split = 0.2)


train_generator = train_datagen.flow_from_directory(dir_,target_size=(100, 100),
                                                   batch_size= 1920,
                                                   class_mode='categorical',
                                                   shuffle=False,
                                                   subset = 'training')

test_generator = train_datagen.flow_from_directory(dir_,
                                                          target_size = (100,100),
                                                          batch_size = 480,
                                                          class_mode = 'categorical',
                                                          shuffle=False,
                                                          subset = 'validation')


# Fetch the data and the labels
x_train, y_train = next(train_generator)
x_test, y_test  = next(test_generator)

# Fix the filepath
test_filepath = []
for filepath in test_generator.filepaths:
    filepath = filepath.replace('\\', '/')
    test_filepath.append(filepath)

from skimage import io
from tensorflow.keras.preprocessing import image

url = '/content/drive/MyDrive/Btrain/100.jpg'

def read_and_transform_img(url):

    img = skimage.io.imread(url)
    img = skimage.transform.resize(img, (224,224))
    
    img = image.img_to_array(img)
    img = np.expand_dims(img, axis=0)

    return img

images = read_and_transform_img(url)

preds = model1.predict(images)
prediction = np.argmax(preds)
pct = np.max(preds)

if prediction == 0:
    print('It\'s Benign!')
elif prediction == 1:
    print('It\'s Malignant!')

print(pct)

from lime import lime_image

explainer = lime_image.LimeImageExplainer()

explanation = explainer.explain_instance(images[0].astype('double'), model1.predict,  
                                         top_labels=3, hide_color=0, num_samples=1000)

from skimage.segmentation import mark_boundaries

temp_1, mask_1 = explanation.get_image_and_mask(explanation.top_labels[0], positive_only=True, num_features=33, hide_rest=True)
temp_2, mask_2 = explanation.get_image_and_mask(explanation.top_labels[0], positive_only=False, num_features=20, hide_rest=False)

fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15,15))
ax1.imshow(mark_boundaries(temp_1, mask_1))
ax2.imshow(mark_boundaries(temp_2, mask_2))
ax1.axis('off')
ax2.axis('off')

#for Malignant
from skimage import io
from tensorflow.keras.preprocessing import image

url = '/content/drive/MyDrive/Mtest/139.jpg'

def read_and_transform_img(url):

    img = skimage.io.imread(url)
    img = skimage.transform.resize(img, (224,224))
    
    img = image.img_to_array(img)
    img = np.expand_dims(img, axis=0)

    return img

images2 = read_and_transform_img(url)

preds = model1.predict(images2)
prediction = np.argmax(preds)
pct = np.max(preds)

if prediction == 0:
    print('It\'s Benign!')
elif prediction == 1:
    print('It\'s Malignant!')

print(pct)

from lime import lime_image

explainer = lime_image.LimeImageExplainer()

explanation = explainer.explain_instance(images2[0].astype('double'), model1.predict,  
                                         top_labels=3, hide_color=0, num_samples=1000)

from skimage.segmentation import mark_boundaries

temp_1, mask_1 = explanation.get_image_and_mask(explanation.top_labels[0], positive_only=True, num_features=15, hide_rest=True)
temp_2, mask_2 = explanation.get_image_and_mask(explanation.top_labels[0], positive_only=False, num_features=50, hide_rest=False)

fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15,15))
ax1.imshow(mark_boundaries(temp_1, mask_1))
ax2.imshow(mark_boundaries(temp_2, mask_2))
ax1.axis('off')
ax2.axis('off')

accuracy_score(np.argmax(X_1, axis=1), np.argmax(Y_val_pred, axis=1))